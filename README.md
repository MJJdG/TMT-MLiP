# TMT-MLiP

Challenge 2, M5 Forecasting: https://www.kaggle.com/c/m5-forecasting-accuracy

Most public notebooks seem to use LGBM (https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc) instead of a NN approach. Good starting point may be this notebook: https://www.kaggle.com/poedator/m5-under-0-50-optimized. 

Some interesting discussions: https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/142129, https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/138881

Temporal Fusion Transformers: https://arxiv.org/pdf/1912.09363.pdf

Max:
- 

Ruben:
- 
  
Taras:
- 

