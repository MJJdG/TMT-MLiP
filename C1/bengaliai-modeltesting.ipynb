{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Starter code used](https://www.kaggle.com/rsmits/keras-efficientnet-b3-training-inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bengaliai-cv19/test_image_data_0.parquet\n",
      "/kaggle/input/bengaliai-cv19/sample_submission.csv\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_3.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_0.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/class_map_corrected.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_3.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_multi_diacritics.csv\n",
      "/kaggle/input/bengaliai-cv19/class_map.csv\n",
      "/kaggle/input/bengaliai-cv19/test.csv\n",
      "/kaggle/input/bengaliai-cv19/train.csv\n",
      "/kaggle/input/weights-v1/Train3_model_43.h5\n",
      "/kaggle/input/weights-v1/Train2_model_23.h5\n",
      "/kaggle/input/weights-v1/Train2_model_29.h5\n",
      "/kaggle/input/weights-v1/Train2_model_12.h5\n",
      "/kaggle/input/weights-v1/Train3_model_35.h5\n",
      "/kaggle/input/weights-v1/Train3_model_36.h5\n",
      "/kaggle/input/weights-v1/Train2_model_4.h5\n",
      "/kaggle/input/weights-v1/Train3_model_24.h5\n",
      "/kaggle/input/weights-v1/Train3_model_23.h5\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Input, load_model\n",
    "from keras.layers import Input, Dense, Lambda, GlobalAveragePooling2D, Reshape, Permute, multiply, AveragePooling2D, MaxPooling2D, BatchNormalization, Conv2D, Dropout, Activation, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import get_source_inputs\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "\n",
    "import cv2 \n",
    "from math import ceil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SEED = 66\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "HEIGHT_NEW = 128\n",
    "WIDTH_NEW = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "BATCH_SIZE = 32 \n",
    "TRAIN_DIR = '.'\n",
    "TEST_SIZE = 1./8\n",
    "EPOCHS = 40\n",
    "\n",
    "RUN_NAME = 'Train1_'\n",
    "PLOT_NAME1 = 'Train1_LossAndAccuracy.png'\n",
    "PLOT_NAME2 = 'Train1_Recall.png'\n",
    "\n",
    "is_keras_tensor = K.is_keras_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Image Preprocessing**\n",
    "\n",
    "[ROI resize](https://www.kaggle.com/shawon10/bangla-graphemes-image-processing-deep-cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_roi(image, size=128):\n",
    "    resized = {}\n",
    "    resize_size=size\n",
    "    \n",
    "    _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "    idx = 0 \n",
    "    ls_xmin = []\n",
    "    ls_ymin = []\n",
    "    ls_xmax = []\n",
    "    ls_ymax = []\n",
    "    for cnt in contours:\n",
    "        idx += 1\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        ls_xmin.append(x)\n",
    "        ls_ymin.append(y)\n",
    "        ls_xmax.append(x + w)\n",
    "        ls_ymax.append(y + h)\n",
    "    xmin = min(ls_xmin)\n",
    "    ymin = min(ls_ymin)\n",
    "    xmax = max(ls_xmax)\n",
    "    ymax = max(ls_ymax)\n",
    "\n",
    "    roi = image[ymin:ymax,xmin:xmax]\n",
    "    resized_roi = cv2.resize(roi, (resize_size, resize_size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return resized_roi\n",
    "\n",
    "# Image Prep\n",
    "def resize_image(img, WIDTH_NEW, HEIGHT_NEW):\n",
    "    # Invert\n",
    "    img = 255 - img\n",
    "\n",
    "    # Normalize\n",
    "    img = (img * (255.0 / img.max())).astype(np.uint8)\n",
    "\n",
    "    # Reshape\n",
    "    img = img.reshape(HEIGHT, WIDTH)\n",
    "    img = resize_roi(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(input_tensor, ratio=16):\n",
    "    \"\"\" Create a channel-wise squeeze-excite block\n",
    "    Args:\n",
    "        input_tensor: input Keras tensor\n",
    "        ratio: number of output filters\n",
    "    Returns: a Keras tensor\n",
    "    References\n",
    "    -   [Squeeze and Excitation Networks](https://arxiv.org/abs/1709.01507)\n",
    "    \"\"\"\n",
    "    init = input_tensor\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = _tensor_shape(init)[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    x = multiply([init, se])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/keras-team/keras-applications/blob/e52c477/keras_applications/imagenet_utils.py#L235-L331\n",
    "def _obtain_input_shape(input_shape,\n",
    "                        default_size,\n",
    "                        min_size,\n",
    "                        data_format,\n",
    "                        require_flatten,\n",
    "                        weights=None):\n",
    "    \"\"\"Internal utility to compute/validate a model's tensor shape.\n",
    "    # Arguments\n",
    "        input_shape: Either None (will return the default network input shape),\n",
    "            or a user-provided shape to be validated.\n",
    "        default_size: Default input width/height for the model.\n",
    "        min_size: Minimum input width/height accepted by the model.\n",
    "        data_format: Image data format to use.\n",
    "        require_flatten: Whether the model is expected to\n",
    "            be linked to a classifier via a Flatten layer.\n",
    "        weights: One of `None` (random initialization)\n",
    "            or 'imagenet' (pre-training on ImageNet).\n",
    "            If weights='imagenet' input channels must be equal to 3.\n",
    "    # Returns\n",
    "        An integer shape tuple (may include None entries).\n",
    "    # Raises\n",
    "        ValueError: In case of invalid argument values.\n",
    "    \"\"\"\n",
    "    if weights != 'imagenet' and input_shape and len(input_shape) == 3:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape[0] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with {input_shape}'\n",
    "                    ' input channels.'.format(input_shape=input_shape[0]))\n",
    "            default_shape = (input_shape[0], default_size, default_size)\n",
    "        else:\n",
    "            if input_shape[-1] not in {1, 3}:\n",
    "                warnings.warn(\n",
    "                    'This model usually expects 1 or 3 input channels. '\n",
    "                    'However, it was passed an input_shape with {n_input_channels}'\n",
    "                    ' input channels.'.format(n_input_channels=input_shape[-1]))\n",
    "            default_shape = (default_size, default_size, input_shape[-1])\n",
    "    else:\n",
    "        if data_format == 'channels_first':\n",
    "            default_shape = (3, default_size, default_size)\n",
    "        else:\n",
    "            default_shape = (default_size, default_size, 3)\n",
    "    if weights == 'imagenet' and require_flatten:\n",
    "        if input_shape is not None:\n",
    "            if input_shape != default_shape:\n",
    "                raise ValueError('When setting `include_top=True` '\n",
    "                                 'and loading `imagenet` weights, '\n",
    "                                 '`input_shape` should be {default_shape}.'.format(default_shape=default_shape))\n",
    "        return default_shape\n",
    "    if input_shape:\n",
    "        if data_format == 'channels_first':\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 3:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of three integers.')\n",
    "                if input_shape[0] != 3 and weights == 'imagenet':\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape={input_shape}`'.format(input_shape=input_shape))\n",
    "                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n",
    "                    (input_shape[2] is not None and input_shape[2] < min_size)):\n",
    "                    raise ValueError('Input size must be at least {min_size}x{min_size};'\n",
    "                                     ' got `input_shape={input_shape}`'.format(min_size=min_size,\n",
    "                                                                               input_shape=input_shape))\n",
    "        else:\n",
    "            if input_shape is not None:\n",
    "                if len(input_shape) != 3:\n",
    "                    raise ValueError(\n",
    "                        '`input_shape` must be a tuple of three integers.')\n",
    "                if input_shape[-1] != 3 and weights == 'imagenet':\n",
    "                    raise ValueError('The input must have 3 channels; got '\n",
    "                                     '`input_shape={input_shape}`'.format(input_shape=input_shape))\n",
    "                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n",
    "                    (input_shape[1] is not None and input_shape[1] < min_size)):\n",
    "                    raise ValueError('Input size must be at least {min_size}x{min_size};'\n",
    "                                     ' got `input_shape={input_shape}`'.format(min_size=min_size,\n",
    "                                                                               input_shape=input_shape))\n",
    "    else:\n",
    "        if require_flatten:\n",
    "            input_shape = default_shape\n",
    "        else:\n",
    "            if data_format == 'channels_first':\n",
    "                input_shape = (3, None, None)\n",
    "            else:\n",
    "                input_shape = (None, None, 3)\n",
    "    if require_flatten:\n",
    "        if None in input_shape:\n",
    "            raise ValueError('If `include_top` is True, '\n",
    "                             'you should specify a static `input_shape`. '\n",
    "                             'Got `input_shape={input_shape}`'.format(input_shape=input_shape))\n",
    "    return input_shape\n",
    "\n",
    "\n",
    "def _tensor_shape(tensor):\n",
    "    return getattr(tensor, '_keras_shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DenseNet models for Keras.\n",
    "# Reference\n",
    "- [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993.pdf)\n",
    "- [The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation](https://arxiv.org/pdf/1611.09326.pdf)\n",
    "\"\"\"\n",
    "def SEDenseNet(input_shape=None,\n",
    "               depth=40,\n",
    "               nb_dense_block=3,\n",
    "               growth_rate=12,\n",
    "               nb_filter=-1,\n",
    "               nb_layers_per_block=-1,\n",
    "               bottleneck=False,\n",
    "               reduction=0.0,\n",
    "               dropout_rate=0.0,\n",
    "               weight_decay=1e-4,\n",
    "               subsample_initial_block=False,\n",
    "               include_top=True,\n",
    "               weights=None,\n",
    "               input_tensor=None,\n",
    "               classes=10,\n",
    "               activation='softmax'):\n",
    "    \"\"\"Instantiate the SE DenseNet architecture\n",
    "        # Arguments\n",
    "            input_shape: optional shape tuple, only to be specified\n",
    "                if `include_top` is False (otherwise the input shape\n",
    "                has to be `(32, 32, 3)` (with `channels_last` dim ordering)\n",
    "                or `(3, 32, 32)` (with `channels_first` dim ordering).\n",
    "                It should have exactly 3 inputs channels,\n",
    "                and width and height should be no smaller than 8.\n",
    "                E.g. `(200, 200, 3)` would be one valid value.\n",
    "            depth: number or layers in the DenseNet\n",
    "            nb_dense_block: number of dense blocks to add to end (generally = 3)\n",
    "            growth_rate: number of filters to add per dense block\n",
    "            nb_filter: initial number of filters. -1 indicates initial\n",
    "                number of filters is 2 * growth_rate\n",
    "            nb_layers_per_block: number of layers in each dense block.\n",
    "                Can be a -1, positive integer or a list.\n",
    "                If -1, calculates nb_layer_per_block from the network depth.\n",
    "                If positive integer, a set number of layers per dense block.\n",
    "                If list, nb_layer is used as provided. Note that list size must\n",
    "                be (nb_dense_block + 1)\n",
    "            bottleneck: flag to add bottleneck blocks in between dense blocks\n",
    "            reduction: reduction factor of transition blocks.\n",
    "                Note : reduction value is inverted to compute compression.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay rate\n",
    "            subsample_initial_block: Set to True to subsample the initial convolution and\n",
    "                add a MaxPool2D before the dense blocks are added.\n",
    "            include_top: whether to include the fully-connected\n",
    "                layer at the top of the network.\n",
    "            weights: one of `None` (random initialization) or\n",
    "                'imagenet' (pre-training on ImageNet)..\n",
    "            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "                to use as image input for the model.\n",
    "            classes: optional number of classes to classify images\n",
    "                into, only to be specified if `include_top` is True, and\n",
    "                if no `weights` argument is specified.\n",
    "            activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'.\n",
    "                Note that if sigmoid is used, classes must be 1.\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "        \"\"\"\n",
    "\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `cifar10` '\n",
    "                         '(pre-training on CIFAR-10).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as ImageNet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    if activation not in ['softmax', 'sigmoid']:\n",
    "        raise ValueError('activation must be one of \"softmax\" or \"sigmoid\"')\n",
    "\n",
    "    if activation == 'sigmoid' and classes != 1:\n",
    "        raise ValueError('sigmoid activation can only be used when classes = 1')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=32,\n",
    "                                      min_size=8,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = __create_dense_net(classes, img_input, include_top, depth, nb_dense_block,\n",
    "                           growth_rate, nb_filter, nb_layers_per_block, bottleneck, reduction,\n",
    "                           dropout_rate, weight_decay, subsample_initial_block, activation)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='se-densenet')\n",
    "\n",
    "    return model\n",
    "\n",
    "def SEDenseNetImageNet169(input_shape=None,\n",
    "                          bottleneck=True,\n",
    "                          reduction=0.5,\n",
    "                          dropout_rate=0.0,\n",
    "                          weight_decay=1e-4,\n",
    "                          include_top=True,\n",
    "                          weights=None,\n",
    "                          input_tensor=None,\n",
    "                          classes=1000,\n",
    "                          activation='softmax'):\n",
    "    return SEDenseNet(input_shape, depth=169, nb_dense_block=4, growth_rate=32, nb_filter=64,\n",
    "                      nb_layers_per_block=[6, 12, 32, 32], bottleneck=bottleneck, reduction=reduction,\n",
    "                      dropout_rate=dropout_rate, weight_decay=weight_decay, subsample_initial_block=True,\n",
    "                      include_top=include_top, weights=weights, input_tensor=input_tensor,\n",
    "                      classes=classes, activation=activation)\n",
    "\n",
    "def __conv_block(ip, nb_filter, bottleneck=False, dropout_rate=None, weight_decay=1e-4):\n",
    "    \"\"\" Apply BatchNorm, Relu, 3x3 Conv2D, optional bottleneck block and dropout\n",
    "    Args:\n",
    "        ip: Input keras tensor\n",
    "        nb_filter: number of filters\n",
    "        bottleneck: add bottleneck block\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: keras tensor with batch_norm, relu and convolution2d added (optional bottleneck)\n",
    "    \"\"\"\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if bottleneck:\n",
    "        inter_channel = nb_filter * 4  # Obtained from https://github.com/liuzhuang13/DenseNet/blob/master/densenet.lua\n",
    "\n",
    "        x = Conv2D(inter_channel, (1, 1), kernel_initializer='he_normal', padding='same', use_bias=False,\n",
    "                   kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(nb_filter, (3, 3), kernel_initializer='he_normal', padding='same', use_bias=False)(x)\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __dense_block(x, nb_layers, nb_filter, growth_rate, bottleneck=False, dropout_rate=None, weight_decay=1e-4,\n",
    "                  grow_nb_filters=True, return_concat_list=False):\n",
    "    \"\"\" Build a dense_block where the output of each conv_block is fed to subsequent ones\n",
    "    Args:\n",
    "        x: keras tensor\n",
    "        nb_layers: the number of layers of conv_block to append to the model.\n",
    "        nb_filter: number of filters\n",
    "        growth_rate: growth rate\n",
    "        bottleneck: bottleneck block\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay factor\n",
    "        grow_nb_filters: flag to decide to allow number of filters to grow\n",
    "        return_concat_list: return the list of feature maps along with the actual output\n",
    "    Returns: keras tensor with nb_layers of conv_block appended\n",
    "    \"\"\"\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x_list = [x]\n",
    "\n",
    "    for i in range(nb_layers):\n",
    "        cb = __conv_block(x, growth_rate, bottleneck, dropout_rate, weight_decay)\n",
    "        x_list.append(cb)\n",
    "\n",
    "        x = concatenate([x, cb], axis=concat_axis)\n",
    "\n",
    "        if grow_nb_filters:\n",
    "            nb_filter += growth_rate\n",
    "\n",
    "    # squeeze and excite block\n",
    "    x = squeeze_excite_block(x)\n",
    "\n",
    "    if return_concat_list:\n",
    "        return x, nb_filter, x_list\n",
    "    else:\n",
    "        return x, nb_filter\n",
    "\n",
    "\n",
    "def __transition_block(ip, nb_filter, compression=1.0, weight_decay=1e-4):\n",
    "    \"\"\" Apply BatchNorm, Relu 1x1, Conv2D, optional compression, dropout and Maxpooling2D\n",
    "    Args:\n",
    "        ip: keras tensor\n",
    "        nb_filter: number of filters\n",
    "        compression: calculated as 1 - reduction. Reduces the number of feature maps\n",
    "                    in the transition block.\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: keras tensor, after applying batch_norm, relu-conv, dropout, maxpool\n",
    "    \"\"\"\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(int(nb_filter * compression), (1, 1), kernel_initializer='he_normal', padding='same', use_bias=False,\n",
    "               kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    # squeeze and excite block\n",
    "    x = squeeze_excite_block(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def __create_dense_net(nb_classes, img_input, include_top, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1,\n",
    "                       nb_layers_per_block=-1, bottleneck=False, reduction=0.0, dropout_rate=None, weight_decay=1e-4,\n",
    "                       subsample_initial_block=False, activation='softmax'):\n",
    "    \"\"\" Build the DenseNet model\n",
    "    Args:\n",
    "        nb_classes: number of classes\n",
    "        img_input: tuple of shape (channels, rows, columns) or (rows, columns, channels)\n",
    "        include_top: flag to include the final Dense layer\n",
    "        depth: number or layers\n",
    "        nb_dense_block: number of dense blocks to add to end (generally = 3)\n",
    "        growth_rate: number of filters to add per dense block\n",
    "        nb_filter: initial number of filters. Default -1 indicates initial number of filters is 2 * growth_rate\n",
    "        nb_layers_per_block: number of layers in each dense block.\n",
    "                Can be a -1, positive integer or a list.\n",
    "                If -1, calculates nb_layer_per_block from the depth of the network.\n",
    "                If positive integer, a set number of layers per dense block.\n",
    "                If list, nb_layer is used as provided. Note that list size must\n",
    "                be (nb_dense_block + 1)\n",
    "        bottleneck: add bottleneck blocks\n",
    "        reduction: reduction factor of transition blocks. Note : reduction value is inverted to compute compression\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay rate\n",
    "        subsample_initial_block: Set to True to subsample the initial convolution and\n",
    "                add a MaxPool2D before the dense blocks are added.\n",
    "        activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'.\n",
    "                Note that if sigmoid is used, classes must be 1.\n",
    "    Returns: keras tensor with nb_layers of conv_block appended\n",
    "    \"\"\"\n",
    "\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    if reduction != 0.0:\n",
    "        assert 1.0 >= reduction > 0.0, 'reduction value must lie between 0.0 and 1.0'\n",
    "\n",
    "    # layers in each dense block\n",
    "    if type(nb_layers_per_block) is list or type(nb_layers_per_block) is tuple:\n",
    "        nb_layers = list(nb_layers_per_block)  # Convert tuple to list\n",
    "\n",
    "        assert len(nb_layers) == nb_dense_block, 'If list, nb_layer is used as provided. ' \\\n",
    "                                                 'Note that list size must be (nb_dense_block)'\n",
    "        final_nb_layer = nb_layers[-1]\n",
    "        nb_layers = nb_layers[:-1]\n",
    "    else:\n",
    "        if nb_layers_per_block == -1:\n",
    "            assert (depth - 4) % 3 == 0, 'Depth must be 3 N + 4 if nb_layers_per_block == -1'\n",
    "            count = int((depth - 4) / 3)\n",
    "            nb_layers = [count for _ in range(nb_dense_block)]\n",
    "            final_nb_layer = count\n",
    "        else:\n",
    "            final_nb_layer = nb_layers_per_block\n",
    "            nb_layers = [nb_layers_per_block] * nb_dense_block\n",
    "\n",
    "    # compute initial nb_filter if -1, else accept users initial nb_filter\n",
    "    if nb_filter <= 0:\n",
    "        nb_filter = 2 * growth_rate\n",
    "\n",
    "    # compute compression factor\n",
    "    compression = 1.0 - reduction\n",
    "\n",
    "    # Initial convolution\n",
    "    if subsample_initial_block:\n",
    "        initial_kernel = (7, 7)\n",
    "        initial_strides = (2, 2)\n",
    "    else:\n",
    "        initial_kernel = (3, 3)\n",
    "        initial_strides = (1, 1)\n",
    "\n",
    "    x = Conv2D(nb_filter, initial_kernel, kernel_initializer='he_normal', padding='same',\n",
    "               strides=initial_strides, use_bias=False, kernel_regularizer=l2(weight_decay))(img_input)\n",
    "\n",
    "    if subsample_initial_block:\n",
    "        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Add dense blocks\n",
    "    for block_idx in range(nb_dense_block - 1):\n",
    "        x, nb_filter = __dense_block(x, nb_layers[block_idx], nb_filter, growth_rate, bottleneck=bottleneck,\n",
    "                                     dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "        # add transition_block\n",
    "        x = __transition_block(x, nb_filter, compression=compression, weight_decay=weight_decay)\n",
    "        nb_filter = int(nb_filter * compression)\n",
    "\n",
    "    # The last dense_block does not have a transition_block\n",
    "    x, nb_filter = __dense_block(x, final_nb_layer, nb_filter, growth_rate, bottleneck=bottleneck,\n",
    "                                 dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    #x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Dense(nb_classes, activation=activation)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized mean pool - GeM\n",
    "gm_exp = tf.Variable(3.0, dtype = tf.float32)\n",
    "def generalized_mean_pool_2d(X):\n",
    "    pool = (tf.reduce_mean(tf.abs(X**(gm_exp)), \n",
    "                        axis = [1, 2], \n",
    "                        keepdims = False) + 1.e-7)**(1./gm_exp)\n",
    "    return pool\n",
    "\n",
    "def create_model(input_shape):\n",
    "    # Input Layer\n",
    "    input_tensor = Input(shape = input_shape)\n",
    "    \n",
    "    x_model = SEDenseNetImageNet169(input_tensor=input_tensor, include_top=False)\n",
    "    \n",
    "    # GeM\n",
    "    lambda_layer = Lambda(generalized_mean_pool_2d)\n",
    "    lambda_layer.trainable_weights.extend([gm_exp])\n",
    "    x = lambda_layer(x_model.output)\n",
    "    \n",
    "    # multi output\n",
    "    grapheme_root = Dense(168, activation = 'softmax', name = 'root')(x)\n",
    "    vowel_diacritic = Dense(11, activation = 'softmax', name = 'vowel')(x)\n",
    "    consonant_diacritic = Dense(7, activation = 'softmax', name = 'consonant')(x)\n",
    "\n",
    "    # model\n",
    "    model = Model(inputs = x_model.input, outputs = [grapheme_root, vowel_diacritic, consonant_diacritic])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = create_model((HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "# Compile Model\n",
    "model1.load_weights('/kaggle/input/weights-v1/Train3_model_43.h5')\n",
    "# Model Summary\n",
    "#print(model1.summary())\n",
    "\n",
    "# # Alternative models\n",
    "# model2 = create_model((HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "# model2.load_weights('/kaggle/input/weights-v1/Train2_model_4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, X, batch_size = 16, img_size = (512, 512, 3), *args, **kwargs):\n",
    "        self.X = X\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return int(ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X = self.__data_generation(indices)\n",
    "        return X\n",
    "    \n",
    "    def __data_generation(self, indices):\n",
    "        X = np.empty((self.batch_size, *self.img_size))\n",
    "        \n",
    "        for i, index in enumerate(indices):\n",
    "            image = self.X[index]\n",
    "            image = np.stack((image,)*CHANNELS, axis=-1)\n",
    "            image = image.reshape(-1, HEIGHT_NEW, WIDTH_NEW, CHANNELS)\n",
    "            \n",
    "            X[i,] = image\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Parquet file directory\n",
    "parquetdir = '/kaggle/input/bengaliai-cv19'\n",
    "\n",
    "# Create Submission File\n",
    "tgt_cols = ['grapheme_root','vowel_diacritic','consonant_diacritic']\n",
    "\n",
    "# Create Predictions\n",
    "row_ids, targets = [], []\n",
    "\n",
    "# Loop through Test Parquet files (X)\n",
    "for i in range(0, 4):\n",
    "    # Test Files Placeholder\n",
    "    test_files = []\n",
    "\n",
    "    # Read Parquet file\n",
    "    df = pd.read_parquet(os.path.join(parquetdir, 'test_image_data_'+str(i)+'.parquet'))\n",
    "    # Get Image Id values\n",
    "    image_ids = df['image_id'].values \n",
    "    # Drop Image_id column\n",
    "    df = df.drop(['image_id'], axis = 1)\n",
    "\n",
    "    # Loop over rows in Dataframe and generate images \n",
    "    X = []\n",
    "    for image_id, index in zip(image_ids, range(df.shape[0])):\n",
    "        test_files.append(image_id)\n",
    "        X.append(resize_image(df.loc[df.index[index]].values, WIDTH_NEW, HEIGHT_NEW))\n",
    "\n",
    "    # Data_Generator\n",
    "    data_generator_test = TestDataGenerator(X, batch_size = BATCH_SIZE, img_size = (HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "        \n",
    "    # Predict with all 3 models\n",
    "    preds1 = model1.predict_generator(data_generator_test, verbose = 1)\n",
    "    #preds2 = model2.predict_generator(data_generator_test, verbose = 1)\n",
    "    \n",
    "    # Loop over Preds    \n",
    "    for i, image_id in zip(range(len(test_files)), test_files):\n",
    "        \n",
    "        for subi, col in zip(range(len(preds1)), tgt_cols):\n",
    "            sub_preds1 = preds1[subi]\n",
    "            #sub_preds2 = preds2[subi]\n",
    "\n",
    "            # Set Prediction with average of 2 predictions\n",
    "            row_ids.append(str(image_id)+'_'+col)\n",
    "            sub_pred_value = np.argmax((sub_preds1[i] ))#+ sub_preds2[i]) / 2)\n",
    "            targets.append(sub_pred_value)\n",
    "    \n",
    "    # Cleanup\n",
    "    del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         row_id  target\n",
      "0          Test_0_grapheme_root       3\n",
      "1        Test_0_vowel_diacritic       0\n",
      "2    Test_0_consonant_diacritic       0\n",
      "3          Test_1_grapheme_root      93\n",
      "4        Test_1_vowel_diacritic       2\n",
      "5    Test_1_consonant_diacritic       0\n",
      "6          Test_2_grapheme_root      19\n",
      "7        Test_2_vowel_diacritic       0\n",
      "8    Test_2_consonant_diacritic       0\n",
      "9          Test_3_grapheme_root     115\n",
      "10       Test_3_vowel_diacritic       0\n",
      "11   Test_3_consonant_diacritic       0\n",
      "12         Test_4_grapheme_root      79\n",
      "13       Test_4_vowel_diacritic       4\n",
      "14   Test_4_consonant_diacritic       0\n",
      "15         Test_5_grapheme_root     115\n",
      "16       Test_5_vowel_diacritic       2\n",
      "17   Test_5_consonant_diacritic       0\n",
      "18         Test_6_grapheme_root     147\n",
      "19       Test_6_vowel_diacritic       9\n",
      "20   Test_6_consonant_diacritic       5\n",
      "21         Test_7_grapheme_root     137\n",
      "22       Test_7_vowel_diacritic       7\n",
      "23   Test_7_consonant_diacritic       0\n",
      "24         Test_8_grapheme_root     119\n",
      "25       Test_8_vowel_diacritic       9\n",
      "26   Test_8_consonant_diacritic       0\n",
      "27         Test_9_grapheme_root     133\n",
      "28       Test_9_vowel_diacritic      10\n",
      "29   Test_9_consonant_diacritic       0\n",
      "30        Test_10_grapheme_root     148\n",
      "31      Test_10_vowel_diacritic       1\n",
      "32  Test_10_consonant_diacritic       4\n",
      "33        Test_11_grapheme_root      21\n",
      "34      Test_11_vowel_diacritic       2\n",
      "35  Test_11_consonant_diacritic       0\n"
     ]
    }
   ],
   "source": [
    "submit_df = pd.DataFrame({'row_id':row_ids,'target':targets}, columns = ['row_id','target'])\n",
    "submit_df.to_csv('submission.csv', index = False)\n",
    "print(submit_df.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
